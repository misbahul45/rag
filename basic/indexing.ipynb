{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c911a9b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ” Apa Itu Indexing dalam RAG\n",
    "\n",
    "**Indexing** adalah proses **mengorganisasi dan menyimpan informasi dari dokumen dalam bentuk yang mudah dicari kembali** ketika dibutuhkan oleh sistem RAG.\n",
    "Dalam konteks RAG, indexing bukan hanya menyimpan teks, tapi **menyimpan pemahaman makna dari teks** (dalam bentuk vektor numerik yang mewakili isi dokumen secara semantik).\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Mengapa Indexing Diperlukan\n",
    "\n",
    "Model bahasa besar (LLM) seperti GPT tidak menyimpan atau mengingat semua informasi eksternal â€” kapasitas memorinya terbatas pada data pelatihan.\n",
    "Ketika kita ingin agar model bisa menjawab pertanyaan berdasarkan sumber eksternal (misalnya kumpulan artikel, jurnal, atau dokumen perusahaan), maka:\n",
    "\n",
    "* Kita **tidak bisa** setiap kali membaca semua dokumen dari awal.\n",
    "* Kita perlu **cara cepat untuk menemukan bagian yang relevan** saja.\n",
    "\n",
    "Di sinilah indexing berperan:\n",
    "Ia membuat sistem dapat **menemukan informasi yang relevan dalam hitungan milidetik** dari ribuan bahkan jutaan potongan data.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Bagaimana Sistematikanya dalam Aliran Data (Data Flow)\n",
    "\n",
    "Proses indexing dalam RAG mengikuti **alur sistematis dari data mentah menjadi data siap pakai untuk pencarian semantik**, seperti ini:\n",
    "\n",
    "1. ### ğŸ§¾ **Pengumpulan Data (Data Collection)**\n",
    "\n",
    "   Sistem mengumpulkan berbagai sumber teks, misalnya artikel blog, dokumen PDF, atau halaman web.\n",
    "   Ini adalah bahan mentah yang nanti akan diindeks.\n",
    "\n",
    "2. ### âœ‚ï¸ **Pemecahan Dokumen (Chunking)**\n",
    "\n",
    "   Dokumen panjang dipecah menjadi bagian kecil agar setiap bagian bisa berdiri sendiri secara makna.\n",
    "   Ini penting karena sistem retrieval bekerja lebih akurat ketika setiap unit informasi cukup spesifik.\n",
    "\n",
    "3. ### ğŸ§¬ **Representasi Semantik (Embedding)**\n",
    "\n",
    "   Setiap potongan teks diubah menjadi representasi matematis (biasanya vektor berdimensi tinggi).\n",
    "   Vektor ini menyimpan *makna semantik*, bukan sekadar kata per kata.\n",
    "\n",
    "   Misalnya, kalimat â€œcara kerja otak buatanâ€ dan â€œmekanisme AI berpikirâ€ akan memiliki representasi yang mirip â€” karena maknanya serupa.\n",
    "\n",
    "4. ### ğŸ—‚ï¸ **Penyimpanan dalam Basis Data Vektor (Vector Store)**\n",
    "\n",
    "   Semua vektor hasil embedding disimpan dalam struktur khusus bernama **vector database** (seperti FAISS, Pinecone, Chroma, dsb).\n",
    "   Database ini memungkinkan sistem mencari kesamaan makna antara teks pertanyaan dan potongan teks yang telah diindeks.\n",
    "\n",
    "5. ### âš¡ **Retrieval**\n",
    "\n",
    "   Ketika pengguna mengajukan pertanyaan, pertanyaan tersebut juga diubah menjadi vektor.\n",
    "   Sistem kemudian mencari potongan teks di dalam index yang paling mirip secara semantik dengan vektor pertanyaan tersebut.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Kegunaan Indexing\n",
    "\n",
    "| Tujuan                                     | Penjelasan                                                                                                                                                |\n",
    "| ------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Efisiensi pencarian**                    | Tanpa indexing, sistem harus membaca seluruh teks setiap kali ada pertanyaan â€” ini sangat lambat. Indexing membuat pencarian bisa dilakukan dengan cepat. |\n",
    "| **Pencocokan makna, bukan kata**           | Karena indexing menggunakan embedding semantik, sistem dapat memahami kesamaan makna meskipun kata-katanya berbeda.                                       |\n",
    "| **Fondasi bagi Retrieval**                 | Index adalah dasar dari proses retrieval. Tanpa index, tidak ada cara efisien untuk menemukan informasi relevan dari data besar.                          |\n",
    "| **Menjembatani LLM dengan data eksternal** | Indexing memungkinkan RAG mengakses dan menggunakan data yang tidak termasuk dalam pelatihan model.                                                       |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© Hubungan Indexing dengan Komponen RAG\n",
    "\n",
    "Sistem RAG terbagi menjadi dua komponen besar:\n",
    "\n",
    "1. **Retrieval (pengambilan informasi)**\n",
    "   Bergantung sepenuhnya pada hasil indexing. Tanpa index yang baik, retrieval akan lambat dan tidak akurat.\n",
    "\n",
    "2. **Generation (pembuatan jawaban)**\n",
    "   Menggunakan hasil retrieval sebagai konteks untuk menghasilkan jawaban yang informatif dan faktual.\n",
    "\n",
    "Dengan kata lain:\n",
    "\n",
    "> **Indexing adalah fondasi yang membuat retrieval mungkin, dan retrieval adalah fondasi yang membuat generasi jawaban relevan.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§­ Analogi untuk Memudahkan\n",
    "\n",
    "Bayangkan kamu punya **perpustakaan besar** dengan ribuan buku.\n",
    "\n",
    "* Jika tidak ada katalog, kamu harus membuka satu per satu buku untuk mencari topik tertentu â€” lambat dan melelahkan.\n",
    "* Jika kamu membuat **katalog tematik**, kamu bisa langsung tahu di rak mana dan halaman mana informasi itu berada.\n",
    "\n",
    "Nah, **indexing adalah pembuatan katalog digital semantik** â€” bukan hanya berdasarkan kata, tapi berdasarkan *makna isi teks*.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”‘ Kesimpulan\n",
    "\n",
    "| Aspek                | Penjelasan Singkat                                                                                 |\n",
    "| -------------------- | -------------------------------------------------------------------------------------------------- |\n",
    "| **Pengertian**       | Proses mengubah teks menjadi bentuk terstruktur dan bermakna agar mudah dicari kembali             |\n",
    "| **Kegunaan**         | Mempercepat pencarian, meningkatkan relevansi hasil, dan memungkinkan RAG mengakses data eksternal |\n",
    "| **Sistematika Data** | Data mentah â†’ Chunk â†’ Embedding â†’ Vector Database â†’ Query & Retrieval                              |\n",
    "| **Fungsi dalam RAG** | Menjadi dasar bagi proses retrieval, yang menyediakan konteks untuk generasi jawaban               |\n",
    "\n",
    "---\n",
    "## ğŸ§  1. Mengapa Kualitas Indexing Penting\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) itu pada dasarnya bekerja dalam dua tahap:\n",
    "\n",
    "1. **Retrieval** â€” menemukan informasi relevan.\n",
    "2. **Generation** â€” membuat jawaban berdasarkan hasil retrieval.\n",
    "\n",
    "Kalau tahap pertama (retrieval) salah atau kurang relevan,\n",
    "maka tahap kedua (generation) juga akan salah arah.\n",
    "\n",
    "> **Kualitas jawaban RAG sangat tergantung pada kualitas indexing.**\n",
    "> Sistem hanya bisa menghasilkan jawaban sebaik konteks yang diambilnya.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ 2. Faktor-Faktor yang Mempengaruhi Kualitas Indexing\n",
    "\n",
    "Mari kita uraikan satu per satu secara konseptual ğŸ‘‡\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© a. **Ukuran dan Tumpang Tindih (Chunk Size & Overlap)**\n",
    "\n",
    "Saat dokumen dipecah menjadi potongan kecil (chunk), dua hal perlu diperhatikan:\n",
    "\n",
    "| Aspek         | Terlalu Kecil            | Terlalu Besar                                 |\n",
    "| ------------- | ------------------------ | --------------------------------------------- |\n",
    "| **Kelebihan** | Relevansi lebih spesifik | Konteks utuh lebih terjaga                    |\n",
    "| **Kelemahan** | Hilang konteks makna     | Sulit ditemukan karena embedding terlalu umum |\n",
    "\n",
    "Idealnya:\n",
    "\n",
    "* **Chunk size**: 300â€“800 kata (tergantung jenis dokumen)\n",
    "* **Overlap**: 10â€“20% antar chunk agar makna tidak terpotong\n",
    "\n",
    "> ğŸ“˜ Contoh:\n",
    "> Kalau kamu mengindeks artikel panjang di Substack, terlalu kecil chunk-nya bisa bikin makna paragraf terpisah dari konteks.\n",
    "> Tapi terlalu besar bisa bikin model kesulitan menentukan bagian mana yang relevan dengan query.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§¬ b. **Kualitas Embedding**\n",
    "\n",
    "Embedding adalah representasi semantik dari teks dalam bentuk vektor numerik.\n",
    "\n",
    "Kualitas embedding menentukan seberapa â€œpintarâ€ sistem memahami makna teks.\n",
    "\n",
    "| Jenis Embedding                                           | Karakteristik                                            |\n",
    "| --------------------------------------------------------- | -------------------------------------------------------- |\n",
    "| **Statistik sederhana (TF-IDF, BM25)**                    | Berdasarkan kata â€” cepat tapi kurang memahami makna      |\n",
    "| **Embedding neural (mis. OpenAI, Cohere, Sentence-BERT)** | Berdasarkan makna â€” lebih akurat dan relevan             |\n",
    "| **Domain-specific embedding**                             | Dilatih untuk bidang tertentu, misalnya medis atau hukum |\n",
    "\n",
    "> Semakin baik embedding, semakin akurat hasil pencarian semantik (semantic search).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ—ƒï¸ c. **Struktur dan Jenis Database**\n",
    "\n",
    "Indexing juga dipengaruhi oleh bagaimana dan di mana data disimpan.\n",
    "\n",
    "| Database                         | Ciri Khas                                    |\n",
    "| -------------------------------- | -------------------------------------------- |\n",
    "| **FAISS**                        | Cepat, cocok untuk eksperimen lokal          |\n",
    "| **Pinecone / Weaviate / Qdrant** | Cloud-based, scalable, mendukung metadata    |\n",
    "| **Chroma**                       | Ringan, cocok untuk project kecil atau lokal |\n",
    "\n",
    "Database ini tidak hanya menyimpan embedding, tapi juga **metadata** (judul, tanggal, sumber, dll) yang bisa membantu sistem menyaring hasil retrieval lebih tepat.\n",
    "\n",
    "---\n",
    "\n",
    "### âš–ï¸ d. **Strategi Preprocessing dan Normalisasi Teks**\n",
    "\n",
    "Sebelum di-*index*, teks biasanya perlu dibersihkan:\n",
    "\n",
    "* Menghapus HTML tag, script, dan simbol aneh\n",
    "* Menormalkan huruf besar/kecil\n",
    "* Menghapus redundansi (misal footer atau navigasi situs)\n",
    "\n",
    "Kalau tidak dibersihkan, hasil embedding bisa â€œberisikâ€ dan menurunkan kualitas pencarian.\n",
    "\n",
    "> Contoh: kalau kamu scrape blog Medium dan tidak buang bagian seperti â€œlogin to continueâ€ atau â€œrelated articlesâ€, embedding-nya akan terdistorsi.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ e. **Kualitas dan Keberagaman Data yang Diindeks**\n",
    "\n",
    "Kalau sumber datanya sempit atau tidak representatif, sistem hanya akan bisa menjawab sebagian kecil pertanyaan dengan baik.\n",
    "\n",
    "Idealnya:\n",
    "\n",
    "* Data yang diindeks **beragam** (berisi berbagai topik dalam domain)\n",
    "* Tapi juga **konsisten secara kualitas** (tidak banyak teks spam, duplikat, atau noise)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” f. **Metode Pencarian (Retrieval Method)**\n",
    "\n",
    "Setelah indexing selesai, metode pencarian juga berpengaruh.\n",
    "\n",
    "Ada dua pendekatan umum:\n",
    "\n",
    "1. **Similarity-based retrieval** â€” cari chunk yang paling mirip dengan query.\n",
    "2. **Hybrid retrieval** â€” gabungkan pencarian semantik (embedding) dan pencarian berbasis kata (keyword).\n",
    "\n",
    "Hybrid biasanya memberikan hasil paling relevan karena menggabungkan â€œpemahaman maknaâ€ dan â€œkecocokan kataâ€.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§­ 3. Dampak Langsung Kualitas Indexing terhadap RAG\n",
    "\n",
    "| Aspek                      | Indexing Buruk                       | Indexing Baik                                     |\n",
    "| -------------------------- | ------------------------------------ | ------------------------------------------------- |\n",
    "| **Kecepatan pencarian**    | Lambat karena data tidak terstruktur | Cepat, hanya mencari di bagian relevan            |\n",
    "| **Akurasi konteks**        | Jawaban salah atau tidak nyambung    | Jawaban relevan dan informatif                    |\n",
    "| **Relevansi semantik**     | Tidak memahami makna sebenarnya      | Mengerti sinonim dan makna tersirat               |\n",
    "| **Kemampuan generalisasi** | Terbatas, banyak â€œmissâ€              | Mampu menjawab dari berbagai formulasi pertanyaan |\n",
    "| **Pengalaman pengguna**    | Frustrasi, tidak dapat jawaban tepat | Lancar, terasa â€œcerdasâ€ dan natural               |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© 4. Inti Hubungan: Indexing â†’ Retrieval â†’ Generation\n",
    "\n",
    "Kamu bisa bayangkan seperti rantai logika:\n",
    "\n",
    "```\n",
    "Indexing yang baik \n",
    "     â†“\n",
    "Retrieval yang akurat \n",
    "     â†“\n",
    "Konteks berkualitas tinggi \n",
    "     â†“\n",
    "Jawaban LLM yang relevan dan faktual\n",
    "```\n",
    "\n",
    "Jadi, RAG bukan hanya soal kemampuan LLM menjawab,\n",
    "tapi juga **seberapa baik sistem memahami dan mengatur pengetahuannya melalui indexing.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Kesimpulan Akhir\n",
    "\n",
    "| Aspek               | Penjelasan Ringkas                                                      |\n",
    "| ------------------- | ----------------------------------------------------------------------- |\n",
    "| **Tujuan utama**    | Membuat informasi dapat dicari dan dipahami secara semantik             |\n",
    "| **Mengapa penting** | Tanpa indexing, RAG tidak bisa mengambil konteks relevan dengan efisien |\n",
    "| **Faktor utama**    | Chunk size, embedding, database, preprocessing, metode retrieval        |\n",
    "| **Dampaknya**       | Langsung menentukan kualitas, relevansi, dan kecepatan jawaban model    |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "903c889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Artikel 1:\n",
      "https://lilianweng.github.io/posts/2021-03-21-lm-toxicity/\n",
      "Content length: 32931\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“˜ Artikel 2:\n",
      "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\n",
      "Content length: 28922\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“˜ Artikel 3:\n",
      "https://lilianweng.github.io/posts/2020-06-07-exploration-drl/\n",
      "Content length: 50155\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“˜ Artikel 4:\n",
      "https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "Content length: 43047\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2021-03-21-lm-toxicity/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\",\n",
    "    \"https://lilianweng.github.io/posts/2020-06-07-exploration-drl/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=urls,\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"ğŸ“˜ Artikel {i}:\")\n",
    "    print(doc.metadata[\"source\"])\n",
    "    print(f\"Content length: {len(doc.page_content)}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-service",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
